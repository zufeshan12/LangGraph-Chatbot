{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a888ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict,Literal,Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph.message import add_messages\n",
    "import sqlite3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd34df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25f3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4faa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chat_node(state:ChatbotState):\n",
    "    \n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\":[response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4015bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sqlite checkpointer to store and preserve chat history across threads\n",
    "conn = sqlite3.Connection(\"chatbot.sqlite\",check_same_thread=False)\n",
    "checkpointer = SqliteSaver(conn=conn)\n",
    "\n",
    "# create graph with nodes and edges\n",
    "graph = StateGraph(ChatbotState)\n",
    "\n",
    "graph.add_node(\"chat_node\",chat_node)\n",
    "\n",
    "graph.add_edge(START,\"chat_node\")\n",
    "graph.add_edge(\"chat_node\",END)\n",
    "\n",
    "# compile graph to create chatbot object\n",
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77403e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is my name?\n",
      "AI: \n",
      "Your name is Zufeshan. How can I help you today?\n",
      "User: what did we talk about?\n",
      "AI: \n",
      "I don’t have the ability to recall past conversations, as each interaction is treated independently and does not retain memory of prior chats. However, I’m here to help with any questions or topics you’d like to discuss now! What do you want to talk about?\n",
      "User: Did i ask you about ASI or AGI?\n",
      "AI: \n",
      "Yes, you asked about AGI (Artificial General Intelligence) and ASI (Artificial Superintelligence). I provided a summary for both concepts. If you'd like more information or have further questions on these topics, feel free to ask!\n",
      "User: quit\n"
     ]
    }
   ],
   "source": [
    "# create a thread id for chat history\n",
    "thread_id = \"1\"\n",
    "# start chatting with AI chatbot\n",
    "while True:\n",
    "    user_query = input(\"type here:\")\n",
    "    print(f\"User: {user_query}\")\n",
    "    \n",
    "    # loop exit criteria\n",
    "    if user_query.strip().lower() in ['exit','bye','end','quit']:\n",
    "        break \n",
    "\n",
    "    #create config for memory allocation to chat history\n",
    "    CONFIG = {'configurable':{'thread_id':thread_id}}\n",
    "    #response = chatbot.invoke({\"messages\": [HumanMessage(content=user_query)]},config=config)\n",
    "    print(f\"AI: \")\n",
    "    for msg_chunk,metadata in chatbot.stream({'messages':HumanMessage(content=user_query)},\n",
    "                                             config=CONFIG,\n",
    "                                             stream_mode=\"messages\"):\n",
    "        if msg_chunk.content:\n",
    "            print(msg_chunk.content,end=\"\",flush=True)\n",
    "    print(end='\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "560395fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is my name?\n",
      "AI: \n",
      "Your name is Alicia. How can I help you today?\n",
      "User: excellent!\n",
      "AI: \n",
      "I’m glad you think so! What’s on your mind today?\n",
      "User: ok bye\n",
      "AI: \n",
      "Goodbye, Alicia! If you have more questions later, feel free to come back. Take care!\n",
      "User: quit\n"
     ]
    }
   ],
   "source": [
    "# create a thread id for chat history\n",
    "thread_id = \"2\"\n",
    "# start chatting with AI chatbot\n",
    "while True:\n",
    "    user_query = input(\"type here:\")\n",
    "    print(f\"User: {user_query}\")\n",
    "    \n",
    "    # loop exit criteria\n",
    "    if user_query.strip().lower() in ['exit','bye','end','quit']:\n",
    "        break \n",
    "\n",
    "    #create config for memory allocation to chat history\n",
    "    CONFIG = {'configurable':{'thread_id':thread_id}}\n",
    "    #response = chatbot.invoke({\"messages\": [HumanMessage(content=user_query)]},config=config)\n",
    "    print(f\"AI: \")\n",
    "    for msg_chunk,metadata in chatbot.stream({'messages':HumanMessage(content=user_query)},\n",
    "                                             config=CONFIG,\n",
    "                                             stream_mode=\"messages\"):\n",
    "        if msg_chunk.content:\n",
    "            print(msg_chunk.content,end=\"\",flush=True)\n",
    "    print(end='\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
