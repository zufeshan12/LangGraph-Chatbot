{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5a888ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict,Literal,Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd34df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a25f3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4faa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chat_node(state:ChatbotState):\n",
    "    \n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\":[response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4015bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add checkpointer to utilize local memory for chat history\n",
    "checkpointer = MemorySaver()\n",
    "# create graph with nodes and edges\n",
    "graph = StateGraph(ChatbotState)\n",
    "\n",
    "graph.add_node(\"chat_node\",chat_node)\n",
    "\n",
    "graph.add_edge(START,\"chat_node\")\n",
    "graph.add_edge(\"chat_node\",END)\n",
    "# compile graph to create chatbot object\n",
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77403e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "AI: \n",
      "Hello! How can I help you today?\n",
      "User: write a brief summary on Artificial Intelligence\n",
      "AI: \n",
      "Artificial Intelligence (AI) is a branch of computer science focused on creating systems that can perform tasks typically requiring human intelligence. This includes abilities such as learning, reasoning, problem-solving, understanding natural language, and recognizing patterns. AI encompasses various subfields, including machine learning, where algorithms improve through experience, and deep learning, which mimics human brain function to analyze complex data.\n",
      "\n",
      "AI applications are widespread, impacting industries like healthcare (for diagnostics and treatment recommendations), finance (for fraud detection and algorithmic trading), transportation (in the development of autonomous vehicles), and entertainment (through personalized content recommendations). While AI offers significant benefits, it also raises ethical and societal concerns, including issues of bias, job displacement, and privacy. As AI technology continues to advance, it remains a transformative force shaping the future of many aspects of life and business.\n",
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "# create a thread id for chat history\n",
    "thread_id = \"1\"\n",
    "# start chatting with AI chatbot\n",
    "while True:\n",
    "    user_query = input(\"type here:\")\n",
    "    print(f\"User: {user_query}\")\n",
    "    \n",
    "    # loop exit criteria\n",
    "    if user_query.strip().lower() in ['exit','bye','end','quit']:\n",
    "        break \n",
    "\n",
    "    #create config for memory allocation to chat history\n",
    "    CONFIG = {'configurable':{'thread_id':thread_id}}\n",
    "    #response = chatbot.invoke({\"messages\": [HumanMessage(content=user_query)]},config=config)\n",
    "    print(f\"AI: \")\n",
    "    for msg_chunk,metadata in chatbot.stream({'messages':HumanMessage(content=user_query)},\n",
    "                                             config=CONFIG,\n",
    "                                             stream_mode=\"messages\"):\n",
    "        if msg_chunk.content:\n",
    "            print(msg_chunk.content,end=\"\",flush=True)\n",
    "    print(end='\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560395fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
